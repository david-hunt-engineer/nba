{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import umap\n",
    "# import s3fs\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pyarrow\n",
    "import boto3\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_scores_2000 = pd.read_parquet('boxscores_raw_2000-01.parquet')\n",
    "raw_scores_2001 = pd.read_parquet('boxscores_raw_2001-02.parquet')\n",
    "raw_scores_2002 = pd.read_parquet('boxscores_raw_2002-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_scores_2000.iloc[:,45:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_factors = ['home_game', 'EFG_PCT', 'FTA_RATE', 'TM_TOV_PCT', 'OREB_PCT',\n",
    "                'OPP_EFG_PCT', 'OPP_FTA_RATE', 'OPP_TOV_PCT', 'OPP_OREB_PCT']\n",
    "four_factors = ['home_game', 'EFG_PCT', 'FTA_RATE', 'TM_TOV_PCT', 'OREB_PCT',\n",
    "                'OPP_EFG_PCT', 'OPP_FTA_RATE', 'OPP_TOV_PCT', 'OPP_OREB_PCT',\n",
    "               'AST_PCT', 'DREB_PCT', 'REB_PCT', 'USG_PCT', 'PIE',\n",
    "               'PCT_FGA_3PT', 'PCT_PTS_2PT_MR', 'PCT_PTS_3PT', 'PCT_PTS_FB', \n",
    "                'PCT_PTS_FT', 'PCT_PTS_OFF_TOV', 'PCT_PTS_PAINT', 'PCT_AST_2PM',\n",
    "               'PCT_AST_3PM', 'PCT_UAST_3PM', 'PCT_AST_FGM', 'PCT_UAST_FGM']\n",
    "\n",
    "info_cols = ['GAME_ID', 'TEAM_ID', 'HOME_TEAM_ID', 'VISITOR_TEAM_ID', 'GAME_DATE_EST', 'PTS', 'ngame']\n",
    "\n",
    "def generate_sequences(input_df, window_length=5):\n",
    "    df = input_df.copy()\n",
    "    \n",
    "    df['ngame'] = df[['GAME_ID']].apply(lambda x: int(x.GAME_ID[-4:]) , axis=1)\n",
    "    df['home_game'] = (df.TEAM_ID == df.HOME_TEAM_ID).astype(int)\n",
    "    df = df[four_factors + info_cols]\n",
    "    df.loc[:, 'GAME_DATE_EST'] = pd.to_datetime(df['GAME_DATE_EST'], format='%Y-%m-%d')\n",
    "\n",
    "    team_a_sequences = np.empty((0, window_length, len(four_factors)))\n",
    "    team_b_sequences = np.empty((0, window_length, len(four_factors)))\n",
    "    targets = np.empty(0)\n",
    "    home_inputs = np.empty(0)\n",
    "    \n",
    "    for game in df.ngame:\n",
    "        home_team, away_team = df.loc[df.ngame == game, ['HOME_TEAM_ID', 'VISITOR_TEAM_ID']].values[0]\n",
    "        \n",
    "        #Keep current game to get target, then remove\n",
    "        home_df = df.loc[(df.TEAM_ID == home_team) & (df.ngame <= game), :]\n",
    "        away_df = df.loc[(df.TEAM_ID == away_team) & (df.ngame <= game), :]\n",
    "        \n",
    "        temp = df.loc[(df.TEAM_ID.isin([away_team, home_team])) & (df.ngame == game), :]\n",
    "        \n",
    "        home_win = int(home_df.loc[home_df.ngame == game, 'PTS'].values[0] > \n",
    "                       away_df.loc[away_df.ngame == game, 'PTS'].values[0])\n",
    "\n",
    "        home_df = home_df.loc[df.ngame < game, :]\n",
    "        away_df = away_df.loc[df.ngame < game, :]\n",
    "\n",
    "        if home_df.shape[0] > window_length and away_df.shape[0] > window_length:\n",
    "            \n",
    "#             home_sequence = np.zeros((window_length, four_factors.shape[0]))\n",
    "            home_sequence = home_df.iloc[:window_length, :][four_factors].values\n",
    "            away_sequence = away_df.iloc[:window_length, :][four_factors].values\n",
    "\n",
    "            team_a_sequences = np.append(team_a_sequences, [home_sequence], axis=0)\n",
    "            team_b_sequences = np.append(team_b_sequences, [away_sequence], axis=0)\n",
    "            home_inputs = np.append(home_inputs, [1])\n",
    "            \n",
    "            team_a_sequences = np.append(team_a_sequences, [away_sequence], axis=0)\n",
    "            team_b_sequences = np.append(team_b_sequences, [home_sequence], axis=0)\n",
    "            home_inputs = np.append(home_inputs, [0])\n",
    "            \n",
    "            targets = np.append(targets, [home_win]*2)\n",
    "            \n",
    "    return team_a_sequences, team_b_sequences, home_inputs, targets\n",
    "\n",
    "Xa_2000, Xb_2000, home_inputs_2000, y_2000 = generate_sequences(raw_scores_2000, 30)\n",
    "Xa_2001, Xb_2001, home_inputs_2001, y_2001 = generate_sequences(raw_scores_2001, 30)\n",
    "\n",
    "# X_2002, y_2002, home_inputs_2002 = generate_sequences(raw_scores_2002, 30)\n",
    "# generate_sequences(raw_scores_2001, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comb = np.concatenate((X_2000, X_2001), axis=0)\n",
    "y_comb = np.concatenate((y_2000, y_2001), axis=0)\n",
    "home_inputs_comb = np.concatenate((home_inputs_2000, home_inputs_2001), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2928/2928 [==============================] - 4s 1ms/step - loss: 0.6762 - acc: 0.6072A: 3s - loss: 0\n",
      "Epoch 2/3\n",
      "2928/2928 [==============================] - 2s 789us/step - loss: 0.6737 - acc: 0.6062\n",
      "Epoch 3/3\n",
      "2928/2928 [==============================] - 2s 796us/step - loss: 0.6717 - acc: 0.6083\n",
      "Train Accuracy: 60.66%\n",
      "Test Accuracy: 57.55%\n"
     ]
    }
   ],
   "source": [
    "def train_sequential(X_train_a, X_train_b, home_input_train, y_train,\n",
    "                     X_test_a, X_test_b, home_input_test, y_test):\n",
    "    np.random.seed(42)\n",
    "        \n",
    "    team_a = Input(shape=(X_train_a.shape[1], X_train_a.shape[2]))\n",
    "    team_b = Input(shape=(X_train_b.shape[1], X_train_b.shape[2]))\n",
    "    \n",
    "    # model = Sequential()\n",
    "    shared_gru = GRU(64) #, input_shape=(X_train_a.shape[1], X_train_b.shape[2]))\n",
    "        \n",
    "    # When we reuse the same layer instance multiple times, the weights of the layer\n",
    "    # are also being reused (it is effectively *the same* layer)\n",
    "    encoded_a = shared_gru(team_a)\n",
    "    encoded_b = shared_gru(team_b)\n",
    "\n",
    "    # We can then concatenate the two vectors:\n",
    "    gru_out = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)\n",
    "    home_input = Input(shape=(1,), name='home_input')\n",
    "    merged_vector = keras.layers.concatenate([gru_out, home_input])\n",
    "\n",
    "    # And add a logistic regression on top\n",
    "    predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "    model = Model(inputs=[team_a, team_b, home_input], outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit([X_train_a, X_train_b, home_input_train], y_train, epochs=3, batch_size=32)   \n",
    "    \n",
    "#         print(model.summary())\n",
    "#     model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
    "    \n",
    "    # Final evaluation of the model\n",
    "    scores_train = model.evaluate([X_train_a, X_train_b, home_input_train], y_train, verbose=0)\n",
    "    scores = model.evaluate([X_test_a, X_test_b, home_input_test], y_test, verbose=0)\n",
    "#     preds_train = model.predict_classes(X_test)\n",
    "\n",
    "    \n",
    "    print(\"Train Accuracy: %.2f%%\" % (scores_train[1]*100))\n",
    "    print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "    #     preds = model. ([X_test_a, X_test_b, home_input_test])\n",
    "    \n",
    "#     print(np.unique(preds_train))\n",
    "#     print(np.unique(preds))\n",
    "\n",
    "train_sequential(Xa_2000, Xb_2000, home_inputs_2000, y_2000,\n",
    "                 Xa_2001, Xb_2001, home_inputs_2001, y_2001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_sequential_basic(X_train, y_train, X_test=None, y_test=None, train_ratio = 0.9):\n",
    "    numpy.random.seed(12)\n",
    "    \n",
    "    if X_test is None:    \n",
    "        train_ratio = 0.9\n",
    "        train_max_idx = int(train_ratio*X.shape[0])\n",
    "\n",
    "        X_test = X_train[train_max_idx:]\n",
    "        y_test = y[train_max_idx:]\n",
    "        \n",
    "        X_train = X_train[:train_max_idx]\n",
    "        y_train = y[:train_max_idx]\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(GRU(100, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Input(input_shape=(X_train.shape[0], 1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
    "    \n",
    "    # Final evaluation of the model\n",
    "    scores_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    preds_train = model.predict_classes(X_test)\n",
    "    preds = model.predict_classes(X_test)\n",
    "    \n",
    "    print(np.unique(preds_train))\n",
    "    print(np.unique(preds))\n",
    "    \n",
    "    print(\"Train Accuracy: %.2f%%\" % (scores_train[1]*100))\n",
    "    print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "train_sequential(X_2000, y_2000, X_2001, y_2001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(model.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 728, 1014], dtype=int64)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test.astype(int))#/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5000)\n",
      "(250, 20, 2)\n",
      "(500, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "def get_sin_cos_sequences(time_steps=20, count_rows=500, f1=1, f2=1.5, a1=1, a2=0.8):\n",
    "    \"\"\"\n",
    "    Generate some dummy data for testing sequence to sequence clustering\n",
    "    - Sine and cosine curves, with parameters provided as function inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.arange(time_steps)\n",
    "    \n",
    "    _, X = np.mgrid[0:count_rows//2, 0:time_steps:1]\n",
    "    targets = np.zeros(count_rows)\n",
    "    targets[:count_rows//2] = 1\n",
    "    rands1 = f1 * 2 * np.pi * np.random.rand(count_rows//2, 1)\n",
    "    rands2 = f2 * 2 * np.pi * np.random.rand(count_rows//2, 1)\n",
    "    \n",
    "    feature_length = 2\n",
    "    \n",
    "    # sequences1a shape: 250, 50\n",
    "    sequences1a =   a1 * np.sin(f1*X*rands1/time_steps)\n",
    "    sequences1b =   np.random.rand(1) * a1 * np.sin(f1*X*rands1/time_steps)\n",
    "    \n",
    "    # Want sequences to be 250, 50, 2\n",
    "    sequences1 = np.concatenate(([np.ravel(sequences1a)], [np.ravel(sequences1b)]), axis=0) \n",
    "    print(sequences1.shape)\n",
    "    sequences1 = sequences1.T.reshape(count_rows//2, time_steps, feature_length)\n",
    "    print(sequences1.shape)\n",
    "\n",
    "    sequences2a =   a2 * np.cos(f2*X*rands2/time_steps)\n",
    "    sequences2b =   np.random.rand(1) * a2* np.cos(f2*X*rands2/time_steps)\n",
    "    sequences2 = np.concatenate(([np.ravel(sequences2a)], [np.ravel(sequences2b)]), axis=0) \n",
    "    sequences2 = sequences2.T.reshape(count_rows//2, time_steps, feature_length)\n",
    "    \n",
    "    sequences = np.concatenate((sequences1, sequences2), axis=0)\n",
    "    print(sequences.shape)\n",
    "    \n",
    "#     for i in range(count_rows//2):\n",
    "#         plt.plot(x, sequences1[i], alpha=0.05)\n",
    "#         plt.plot(x, sequences1b[i], alpha=0.05)\n",
    "#         plt.plot(x, sequences2[i], alpha=0.05)\n",
    "\n",
    "#     plt.xlabel('sample(n)')\n",
    "#     plt.ylabel('voltage(V)')\n",
    "#     plt.show()\n",
    "    \n",
    "#     sequences = np.vstack([sequences1, sequences2])\n",
    "    return sequences, targets #sequences.reshape(count_rows, time_steps, 1)\n",
    "#     \n",
    "X_dummy, y_dummy = get_sin_cos_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1754, 20, 5)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_26 (GRU)                 (None, 100)               30900     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 31,001\n",
      "Trainable params: 31,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.6399 - acc: 0.6300\n",
      "Epoch 2/3\n",
      "500/500 [==============================] - 0s 566us/step - loss: 0.2560 - acc: 0.9240\n",
      "Epoch 3/3\n",
      "500/500 [==============================] - 0s 586us/step - loss: 0.0571 - acc: 0.9840\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(12)\n",
    "\n",
    "train_ratio = 0.9\n",
    "train_max_idx = int(train_ratio*X.shape[0])\n",
    "\n",
    "# X_train = X[:train_max_idx]\n",
    "# y_train = y[:train_max_idx]\n",
    "# X_test = X[train_max_idx:]\n",
    "# y_test = y[train_max_idx:]\n",
    "print(X.shape)\n",
    "\n",
    "def train_sequential_dummy(X, y):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(100, input_shape=(X.shape[1],X.shape[2])))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    model.fit(X, y, epochs=3, batch_size=32)\n",
    "    # Final evaluation of the model\n",
    "    scores = model.evaluate(X, y, verbose=0)\n",
    "    preds = model.predict(X)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    \n",
    "train_sequential_dummy(X_dummy, y_dummy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
